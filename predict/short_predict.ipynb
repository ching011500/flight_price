{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é æ¸¬åƒ¹æ ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹[xgb] æ¸¬è©¦é›† MSE = 0.0546, R2 = 0.8535\n",
      "ğŸ”¹[rf] æ¸¬è©¦é›† MSE = 0.0092, R2 = 0.8909\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/eco_BKK.csvï¼ˆå…± 140 ç­†ï¼‰\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/eco_GMP.csvï¼ˆå…± 21 ç­†ï¼‰\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/eco_HKG.csvï¼ˆå…± 405 ç­†ï¼‰\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/eco_HND.csvï¼ˆå…± 52 ç­†ï¼‰\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/eco_ICN.csvï¼ˆå…± 102 ç­†ï¼‰\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/eco_NRT.csvï¼ˆå…± 180 ç­†ï¼‰\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/eco_SIN.csvï¼ˆå…± 86 ç­†ï¼‰\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/biz_BKK.csvï¼ˆå…± 80 ç­†ï¼‰\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/biz_GMP.csvï¼ˆå…± 7 ç­†ï¼‰\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/biz_HKG.csvï¼ˆå…± 140 ç­†ï¼‰\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/biz_HND.csvï¼ˆå…± 37 ç­†ï¼‰\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/biz_ICN.csvï¼ˆå…± 58 ç­†ï¼‰\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/biz_NRT.csvï¼ˆå…± 98 ç­†ï¼‰\n",
      "âœ… æ¸¬è©¦é›†å·²å­˜ï¼špredict_data/short/biz_SIN.csvï¼ˆå…± 43 ç­†ï¼‰\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# --------------------------\n",
    "# 1. è®€å–è³‡æ–™\n",
    "# --------------------------\n",
    "df = pd.read_csv('/Users/yuchingchen/Documents/å°ˆé¡Œ/cleaned_data/short_flight.csv')\n",
    "\n",
    "# --------------------------\n",
    "# 2. æ¬„ä½å®šç¾©\n",
    "# --------------------------\n",
    "cat_cols  = ['å‡ºç™¼æ™‚æ®µ','å‡ºç™¼æ©Ÿå ´ä»£è™Ÿ','æŠµé”æ™‚æ®µ','èˆªç©ºè¯ç›Ÿ','æ©Ÿå‹åˆ†é¡','å‡æœŸ','æ˜¯å¦ç‚ºå¹³æ—¥']\n",
    "group_col = 'æŠµé”æ©Ÿå ´ä»£è™Ÿ'\n",
    "num_cols  = ['é£›è¡Œæ™‚é–“_åˆ†é˜','ç¶“æ¿ŸæŒ‡æ¨™','æ©Ÿå ´æŒ‡æ¨™','competing_flights']\n",
    "log_col   = 'å¹³å‡åƒ¹æ ¼_log'\n",
    "true_col  = 'å¹³å‡åƒ¹æ ¼'\n",
    "pred_col  = 'é æ¸¬_å¹³å‡åƒ¹æ ¼'\n",
    "\n",
    "# --------------------------\n",
    "# 3. åˆ†è‰™ç­‰ä¸¦æ¨™è¨˜çœŸå¯¦åƒ¹æ ¼\n",
    "# --------------------------\n",
    "eco_raw = df[df['è‰™ç­‰']=='ç¶“æ¿Ÿè‰™'][cat_cols + [group_col] + num_cols + [log_col] + [true_col]].copy()\n",
    "biz_raw = df[df['è‰™ç­‰']=='å•†å‹™è‰™'][cat_cols + [group_col] + num_cols + [log_col] + [true_col]].copy()\n",
    "\n",
    "# --------------------------\n",
    "# 4. ç·¨ç¢¼èˆ‡æ¨™æº–åŒ–\n",
    "# --------------------------\n",
    "def encode_and_scale(df_raw):\n",
    "    df_enc = pd.get_dummies(df_raw, columns=cat_cols, drop_first=True)\n",
    "    scaler = StandardScaler()\n",
    "    df_enc[num_cols] = scaler.fit_transform(df_enc[num_cols])\n",
    "    return df_enc, scaler\n",
    "\n",
    "eco_enc, eco_scaler = encode_and_scale(eco_raw)\n",
    "biz_enc, biz_scaler = encode_and_scale(biz_raw)\n",
    "\n",
    "# --------------------------\n",
    "# 5. å–å…±åŒç‰¹å¾µæ¬„ä½\n",
    "# --------------------------\n",
    "common_feats = list(set(eco_enc.columns) & set(biz_enc.columns))\n",
    "for col in [log_col, true_col, group_col]:\n",
    "    if col in common_feats:\n",
    "        common_feats.remove(col)\n",
    "\n",
    "# --------------------------\n",
    "# 6. è¨“ç·´æ¨¡å‹ & æ‹†åˆ†æ¸¬è©¦é›†\n",
    "# --------------------------\n",
    "def split_and_train(df_enc, model_type='xgb', seed=123):\n",
    "    X = df_enc[common_feats]\n",
    "    y = df_enc[log_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        model = XGBRegressor(n_estimators=100, random_state=seed, n_jobs=-1)\n",
    "    else:\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=seed, n_jobs=-1)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"ğŸ”¹[{model_type}] æ¸¬è©¦é›† MSE = {mean_squared_error(y_test, y_pred):.4f}, R2 = {r2_score(y_test, y_pred):.4f}\")\n",
    "    sigma2 = np.mean((y_test - y_pred)**2)\n",
    "    \n",
    "    return model, sigma2, df_enc.loc[X_test.index]\n",
    "\n",
    "eco_model, sigma2_eco, eco_test = split_and_train(eco_enc, model_type='xgb')\n",
    "biz_model, sigma2_biz, biz_test = split_and_train(biz_enc, model_type='rf')\n",
    "\n",
    "# --------------------------\n",
    "# 7. çœŸå¯¦çµ„åˆèˆ‡é æ¸¬å„²å­˜\n",
    "# --------------------------\n",
    "def get_unique_combinations(df_raw, code):\n",
    "    sub = df_raw[df_raw[group_col] == code]\n",
    "    return sub[cat_cols + num_cols + [true_col]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "def predict_and_save_testset(test_df, model, scaler, sigma2, prefix):\n",
    "    out_dir = 'predict_data/short'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for code in sorted(test_df[group_col].unique()):\n",
    "        combos = get_unique_combinations(test_df, code)\n",
    "        if combos.empty:\n",
    "            continue\n",
    "\n",
    "        enc = pd.get_dummies(combos, columns=cat_cols, drop_first=True)\n",
    "        enc = enc.reindex(columns=common_feats, fill_value=0)\n",
    "        enc[num_cols] = scaler.transform(combos[num_cols])\n",
    "        log_preds = model.predict(enc)\n",
    "        combos[pred_col] = np.expm1(log_preds + 0.5 * sigma2)\n",
    "        combos[group_col] = code\n",
    "        combos = combos.drop_duplicates(subset=cat_cols + num_cols)\n",
    "        fn = f'{out_dir}/{prefix}_{code}.csv'\n",
    "        combos.to_csv(fn, index=False)\n",
    "        print(f\"âœ… æ¸¬è©¦é›†å·²å­˜ï¼š{fn}ï¼ˆå…± {len(combos)} ç­†ï¼‰\")\n",
    "\n",
    "# --------------------------\n",
    "# 8. åŸ·è¡Œæ¸¬è©¦é›†é æ¸¬\n",
    "# --------------------------\n",
    "predict_and_save_testset(eco_raw.loc[eco_test.index], eco_model, eco_scaler, sigma2_eco, 'eco')\n",
    "predict_and_save_testset(biz_raw.loc[biz_test.index], biz_model, biz_scaler, sigma2_biz, 'biz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
