{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‰ø°Ë≥¥ÂçÄÈñì"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF + Bootstrap CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap RF (economy): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [04:30<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä [economy] RF Áµ±Ë®àÊåáÊ®ôÔºö\n",
      "   MSE         = 41595028.71\n",
      "   R^2         = 0.9506\n",
      "   95% Ë¶ÜËìãÁéá   = 48.31%\n",
      "   99% Ë¶ÜËìãÁéá   = 58.13%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap RF (business): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [03:11<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä [business] RF Áµ±Ë®àÊåáÊ®ôÔºö\n",
      "   MSE         = 210566918.90\n",
      "   R^2         = 0.9108\n",
      "   95% Ë¶ÜËìãÁéá   = 50.27%\n",
      "   99% Ë¶ÜËìãÁéá   = 60.21%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === ËºâÂÖ•ÂéüÂßãË≥áÊñô ===\n",
    "file_path = '/Users/yuchingchen/Documents/Â∞àÈ°å/cleaned_data/long_flight.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# ÂàÜÈõ¢Á∂ìÊøüËâôËàáÈùûÁ∂ìÊøüËâôÁöÑÊï∏Êìö\n",
    "economy_data = data[data[\"ËâôÁ≠âÔºà‰∏ªËà™ÊÆµÔºâ\"] == \"Á∂ìÊøüËâô\"]\n",
    "business_data = data[data[\"ËâôÁ≠âÔºà‰∏ªËà™ÊÆµÔºâ\"] == \"ÂïÜÂãôËâô\"]\n",
    "\n",
    "# One-hot encodingÔºöÈáùÂ∞çÂ§öÂÄãÂàÜÈ°ûÊ¨Ñ‰ΩçÈÄ≤Ë°åËôïÁêÜ\n",
    "categorical_cols = ['ÊòüÊúü', 'Âá∫ÁôºÊôÇÊÆµ', 'Âá∫ÁôºÊ©üÂ†¥‰ª£Ëôü', 'ÊäµÈÅîÊôÇÊÆµ', 'ÊäµÈÅîÊ©üÂ†¥‰ª£Ëôü',\n",
    "                    'Ëà™Á©∫ÂÖ¨Âè∏ÁµÑÂêà', 'Ëà™Á©∫ËÅØÁõü', 'ÂÅúÈù†Á´ôÊï∏Èáè', 'ÊòØÂê¶ÈÅéÂ§ú', 'ÊòØÂê¶ÁÇ∫Âπ≥Êó•', \n",
    "                    'Ê©üÂûãÂàÜÈ°û', 'ÂÅáÊúü', 'Region', 'È£õË°åÊôÇÈñìÂÖ©ÊÆµÂàÜÈ°û']\n",
    "economy_data = pd.get_dummies(economy_data, columns=categorical_cols, drop_first=True)\n",
    "business_data = pd.get_dummies(business_data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Êï∏ÂÄºÂûãÁâπÂæµÊ®ôÊ∫ñÂåñ\n",
    "num_cols = ['ÂÅúÁïôÊôÇÈñì_ÂàÜÈêò', 'È£õË°åÊôÇÈñì_ÂàÜÈêò', 'ÂØ¶ÈöõÈ£õË°åÊôÇÈñì_ÂàÜÈêò', 'Á∂ìÊøüÊåáÊ®ô', 'Ê©üÂ†¥ÊåáÊ®ô', 'competing_flights']\n",
    "scaler = StandardScaler()\n",
    "economy_data[num_cols] = scaler.fit_transform(economy_data[num_cols])\n",
    "business_data[num_cols] = scaler.transform(business_data[num_cols])\n",
    "\n",
    "# Á¢∫‰øùÂÖ©ÂÄãÊï∏ÊìöÈõÜÊìÅÊúâÁõ∏ÂêåÁöÑÁâπÂæµÊ¨Ñ‰Ωç\n",
    "common_cols = list(set(economy_data.columns) & set(business_data.columns))\n",
    "economy_data = economy_data[common_cols]\n",
    "business_data = business_data[common_cols]\n",
    "\n",
    "# ÈÅ∏ÂèñÂª∫Ê®°ÁâπÂæµÔºöÂÖàÊåëÈÅ∏ dummy Ê¨Ñ‰ΩçÔºåÂÜçÂä†‰∏äÊï∏ÂÄºÂûãÁâπÂæµ\n",
    "target_col = 'ÊúÄ‰ΩéÂÉπÊ†º_log'\n",
    "target_keywords = ['Âá∫ÁôºÊôÇÊÆµ_', 'Âá∫ÁôºÊ©üÂ†¥‰ª£Ëôü_', 'ÊäµÈÅîÊôÇÊÆµ_', 'Ëà™Á©∫ÂÖ¨Âè∏ÁµÑÂêà_', 'Ëà™Á©∫ËÅØÁõü_', 'ÂÅúÈù†Á´ôÊï∏Èáè_', \n",
    "                   'Ê©üÂûãÂàÜÈ°û_', 'ÂÅáÊúü_', 'È£õË°åÊôÇÈñìÂÖ©ÊÆµÂàÜÈ°û_']\n",
    "economy_data_dummy_cols = [col for col in economy_data.columns if any(keyword in col for keyword in target_keywords)]\n",
    "business_data_dummy_cols = [col for col in business_data.columns if any(keyword in col for keyword in target_keywords)]\n",
    "eco_features = economy_data_dummy_cols + ['ÂÅúÁïôÊôÇÈñì_ÂàÜÈêò', 'ÂØ¶ÈöõÈ£õË°åÊôÇÈñì_ÂàÜÈêò', 'Á∂ìÊøüÊåáÊ®ô', 'Ê©üÂ†¥ÊåáÊ®ô', 'competing_flights']\n",
    "biz_features = business_data_dummy_cols + ['ÂÅúÁïôÊôÇÈñì_ÂàÜÈêò', 'ÂØ¶ÈöõÈ£õË°åÊôÇÈñì_ÂàÜÈêò', 'Á∂ìÊøüÊåáÊ®ô', 'Ê©üÂ†¥ÊåáÊ®ô', 'competing_flights']\n",
    "\n",
    "# Bootstrap È†êÊ∏¨ÂçÄÈñìÔºà95% + 99%ÔºâËàá‰ø°ÂøÉË©ïÂàÜ\n",
    "def bootstrap_prediction_ci_rf(X, y_log, label=\"economy\", n_iterations=100):\n",
    "    X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.3, random_state=123)\n",
    "    y_test = np.exp(y_test_log.values)\n",
    "    all_log_preds = []\n",
    "\n",
    "    for i in tqdm(range(n_iterations), desc=f\"Bootstrap RF ({label})\"):\n",
    "        X_resample, y_resample = resample(X_train, y_train_log, replace=True, random_state=100+i)\n",
    "        model = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=100+i)\n",
    "        model.fit(X_resample, y_resample)\n",
    "        pred_log = model.predict(X_test)\n",
    "        all_log_preds.append(pred_log)\n",
    "\n",
    "    all_log_preds = np.array(all_log_preds)\n",
    "    mean_log_pred = np.mean(all_log_preds, axis=0)\n",
    "    mean_pred = np.exp(mean_log_pred)\n",
    "\n",
    "    # CI in log space\n",
    "    ci_95_lower_log = np.percentile(all_log_preds, 2.5, axis=0)\n",
    "    ci_95_upper_log = np.percentile(all_log_preds, 97.5, axis=0)\n",
    "    ci_99_lower_log = np.percentile(all_log_preds, 0.5, axis=0)\n",
    "    ci_99_upper_log = np.percentile(all_log_preds, 99.5, axis=0)\n",
    "\n",
    "    # exp back\n",
    "    ci_95_lower = np.exp(ci_95_lower_log)\n",
    "    ci_95_upper = np.exp(ci_95_upper_log)\n",
    "    ci_99_lower = np.exp(ci_99_lower_log)\n",
    "    ci_99_upper = np.exp(ci_99_upper_log)\n",
    "\n",
    "    # ÊòØÂê¶ËêΩÂú®ÂçÄÈñì\n",
    "    cover_95 = (y_test >= ci_95_lower) & (y_test <= ci_95_upper)\n",
    "    cover_99 = (y_test >= ci_99_lower) & (y_test <= ci_99_upper)\n",
    "\n",
    "    # ‰ø°ÂøÉË©ï‰º∞ÔºöËàá CI ‰∏≠ÂøÉË∑ùÈõ¢‰ΩîÂçÄÈñìÊØî‰æã\n",
    "    ci_center = (ci_95_upper + ci_95_lower) / 2\n",
    "    ci_width = ci_95_upper - ci_95_lower\n",
    "    confidence_score = 1 - np.abs(y_test - ci_center) / (ci_width + 1e-8)\n",
    "    confidence_score = np.clip(confidence_score, 0, 1)\n",
    "\n",
    "    # Áµ±Ë®àÊåáÊ®ô\n",
    "    mse = mean_squared_error(y_test, mean_pred)\n",
    "    r2 = r2_score(y_test, mean_pred)\n",
    "    cover_95_ratio = cover_95.mean()\n",
    "    cover_99_ratio = cover_99.mean()\n",
    "\n",
    "    print(f\"\\nüìä [{label}] RF Áµ±Ë®àÊåáÊ®ôÔºö\")\n",
    "    print(f\"   MSE         = {mse:.2f}\")\n",
    "    print(f\"   R^2         = {r2:.4f}\")\n",
    "    print(f\"   95% Ë¶ÜËìãÁéá   = {cover_95_ratio:.2%}\")\n",
    "    print(f\"   99% Ë¶ÜËìãÁéá   = {cover_99_ratio:.2%}\\n\")\n",
    "\n",
    "    df_result = pd.DataFrame({\n",
    "        \"ÂØ¶ÈöõÂÉπÊ†º\": y_test,\n",
    "        \"È†êÊ∏¨ÂÄº\": mean_pred,\n",
    "        \"CI95‰∏ãÈôê\": ci_95_lower,\n",
    "        \"CI95‰∏äÈôê\": ci_95_upper,\n",
    "        \"CI99‰∏ãÈôê\": ci_99_lower,\n",
    "        \"CI99‰∏äÈôê\": ci_99_upper,\n",
    "        \"CI95Èï∑Â∫¶\": ci_95_upper - ci_95_lower,\n",
    "        \"CI99Èï∑Â∫¶\": ci_99_upper - ci_99_lower,\n",
    "        \"ÊòØÂê¶ËêΩÂú®CI95\": cover_95.astype(int),\n",
    "        \"ÊòØÂê¶ËêΩÂú®CI99\": cover_99.astype(int),\n",
    "        \"‰ø°ÂøÉÂàÜÊï∏\": confidence_score\n",
    "    })\n",
    "\n",
    "# Âü∑Ë°åÁ∂ìÊøüËâôËàáÂïÜÂãôËâô RF Ê®°Âûã\n",
    "bootstrap_prediction_ci_rf(economy_data[eco_features], economy_data[target_col], label=\"economy\")\n",
    "bootstrap_prediction_ci_rf(business_data[biz_features], business_data[target_col], label=\"business\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB + Bootstrap CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap (economy): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [02:31<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä [economy] Áµ±Ë®àÊåáÊ®ôÔºö\n",
      "   MSE         = 50305390.93\n",
      "   R^2         = 0.9402\n",
      "   95% Ë¶ÜËìãÁéá   = 55.67%\n",
      "   99% Ë¶ÜËìãÁéá   = 67.87%\n",
      "\n",
      "‚úÖ [economy] Bootstrap CI ÁµêÊûúÁî¢ÁîüÂÆåÊàêÔºÅ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrap (business): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [02:34<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä [business] Áµ±Ë®àÊåáÊ®ôÔºö\n",
      "   MSE         = 239298881.63\n",
      "   R^2         = 0.8986\n",
      "   95% Ë¶ÜËìãÁéá   = 61.92%\n",
      "   99% Ë¶ÜËìãÁéá   = 73.83%\n",
      "\n",
      "‚úÖ [business] Bootstrap CI ÁµêÊûúÁî¢ÁîüÂÆåÊàêÔºÅ\n",
      "‚úÖ Ê∏¨Ë©¶ÈõÜÔºàÊúâÈ†êÊ∏¨ÂçÄÈñìÔºâÁµêÊûúÂ∑≤Â≠òÊ™îÔºö/Users/yuchingchen/Documents/Â∞àÈ°å/ci/ci_data/long_xgb_with_ci.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === ËºâÂÖ•ÂéüÂßãË≥áÊñô ===\n",
    "file_path = '/Users/yuchingchen/Documents/Â∞àÈ°å/cleaned_data/long_flight.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# ÂàÜÈõ¢Á∂ìÊøüËâôËàáÈùûÁ∂ìÊøüËâôÁöÑÊï∏Êìö\n",
    "economy_data = data[data[\"ËâôÁ≠âÔºà‰∏ªËà™ÊÆµÔºâ\"] == \"Á∂ìÊøüËâô\"]\n",
    "business_data = data[data[\"ËâôÁ≠âÔºà‰∏ªËà™ÊÆµÔºâ\"] == \"ÂïÜÂãôËâô\"]\n",
    "\n",
    "# One-hot encodingÔºöÈáùÂ∞çÂ§öÂÄãÂàÜÈ°ûÊ¨Ñ‰ΩçÈÄ≤Ë°åËôïÁêÜ\n",
    "categorical_cols = ['ÊòüÊúü', 'Âá∫ÁôºÊôÇÊÆµ', 'Âá∫ÁôºÊ©üÂ†¥‰ª£Ëôü', 'ÊäµÈÅîÊôÇÊÆµ', 'ÊäµÈÅîÊ©üÂ†¥‰ª£Ëôü',\n",
    "                    'Ëà™Á©∫ÂÖ¨Âè∏ÁµÑÂêà', 'Ëà™Á©∫ËÅØÁõü', 'ÂÅúÈù†Á´ôÊï∏Èáè', 'ÊòØÂê¶ÈÅéÂ§ú', 'ÊòØÂê¶ÁÇ∫Âπ≥Êó•', \n",
    "                    'Ê©üÂûãÂàÜÈ°û', 'ÂÅáÊúü', 'Region', 'È£õË°åÊôÇÈñìÂÖ©ÊÆµÂàÜÈ°û']\n",
    "economy_data = pd.get_dummies(economy_data, columns=categorical_cols, drop_first=True)\n",
    "business_data = pd.get_dummies(business_data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Êï∏ÂÄºÂûãÁâπÂæµÊ®ôÊ∫ñÂåñ\n",
    "num_cols = ['ÂÅúÁïôÊôÇÈñì_ÂàÜÈêò', 'È£õË°åÊôÇÈñì_ÂàÜÈêò', 'ÂØ¶ÈöõÈ£õË°åÊôÇÈñì_ÂàÜÈêò', 'Á∂ìÊøüÊåáÊ®ô', 'Ê©üÂ†¥ÊåáÊ®ô', 'competing_flights']\n",
    "scaler = StandardScaler()\n",
    "economy_data[num_cols] = scaler.fit_transform(economy_data[num_cols])\n",
    "business_data[num_cols] = scaler.transform(business_data[num_cols])\n",
    "\n",
    "# Á¢∫‰øùÂÖ©ÂÄãÊï∏ÊìöÈõÜÊìÅÊúâÁõ∏ÂêåÁöÑÁâπÂæµÊ¨Ñ‰Ωç\n",
    "common_cols = list(set(economy_data.columns) & set(business_data.columns))\n",
    "economy_data = economy_data[common_cols]\n",
    "business_data = business_data[common_cols]\n",
    "\n",
    "# ÈÅ∏ÂèñÂª∫Ê®°ÁâπÂæµÔºöÂÖàÊåëÈÅ∏ dummy Ê¨Ñ‰ΩçÔºåÂÜçÂä†‰∏äÊï∏ÂÄºÂûãÁâπÂæµ\n",
    "target_col = 'ÊúÄ‰ΩéÂÉπÊ†º_log'\n",
    "target_keywords = ['Âá∫ÁôºÊôÇÊÆµ_', 'Âá∫ÁôºÊ©üÂ†¥‰ª£Ëôü_', 'ÊäµÈÅîÊôÇÊÆµ_', 'Ëà™Á©∫ÂÖ¨Âè∏ÁµÑÂêà_', 'Ëà™Á©∫ËÅØÁõü_', 'ÂÅúÈù†Á´ôÊï∏Èáè_', \n",
    "                   'Ê©üÂûãÂàÜÈ°û_', 'ÂÅáÊúü_', 'È£õË°åÊôÇÈñìÂÖ©ÊÆµÂàÜÈ°û_']\n",
    "economy_data_dummy_cols = [col for col in economy_data.columns if any(keyword in col for keyword in target_keywords)]\n",
    "business_data_dummy_cols = [col for col in business_data.columns if any(keyword in col for keyword in target_keywords)]\n",
    "eco_features = economy_data_dummy_cols + ['ÂÅúÁïôÊôÇÈñì_ÂàÜÈêò', 'ÂØ¶ÈöõÈ£õË°åÊôÇÈñì_ÂàÜÈêò', 'Á∂ìÊøüÊåáÊ®ô', 'Ê©üÂ†¥ÊåáÊ®ô', 'competing_flights']\n",
    "biz_features = business_data_dummy_cols + ['ÂÅúÁïôÊôÇÈñì_ÂàÜÈêò', 'ÂØ¶ÈöõÈ£õË°åÊôÇÈñì_ÂàÜÈêò', 'Á∂ìÊøüÊåáÊ®ô', 'Ê©üÂ†¥ÊåáÊ®ô', 'competing_flights']\n",
    "\n",
    "# ‰øÆÊîπÂæåÁöÑ bootstrap ÂáΩÂºèÔºöÂà©Áî® X_test ÁöÑ index Áî¢ÁîüÁµêÊûú DataFrame\n",
    "def bootstrap_prediction_ci(X, y_log, label=\"economy\", n_iterations=500):\n",
    "    X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.3, random_state=123)\n",
    "    y_test = np.exp(y_test_log.values)\n",
    "    all_log_preds = []\n",
    "\n",
    "    for i in tqdm(range(n_iterations), desc=f\"Bootstrap ({label})\"):\n",
    "        X_resample, y_resample = resample(X_train, y_train_log, replace=True, random_state=100+i)\n",
    "        model = XGBRegressor(n_estimators=100, n_jobs=-1, random_state=100+i)\n",
    "        model.fit(X_resample, y_resample)\n",
    "        pred_log = model.predict(X_test)\n",
    "        all_log_preds.append(pred_log)\n",
    "\n",
    "    all_log_preds = np.array(all_log_preds)\n",
    "    mean_log_pred = np.mean(all_log_preds, axis=0)\n",
    "    mean_pred = np.exp(mean_log_pred)\n",
    "\n",
    "    # CI Âú® log Á©∫ÈñìË®àÁÆó\n",
    "    ci_95_lower_log = np.percentile(all_log_preds, 2.5, axis=0)\n",
    "    ci_95_upper_log = np.percentile(all_log_preds, 97.5, axis=0)\n",
    "    ci_99_lower_log = np.percentile(all_log_preds, 0.5, axis=0)\n",
    "    ci_99_upper_log = np.percentile(all_log_preds, 99.5, axis=0)\n",
    "\n",
    "    # ËΩâÂõûÂéüÂßãÁ©∫Èñì\n",
    "    ci_95_lower = np.exp(ci_95_lower_log)\n",
    "    ci_95_upper = np.exp(ci_95_upper_log)\n",
    "    ci_99_lower = np.exp(ci_99_lower_log)\n",
    "    ci_99_upper = np.exp(ci_99_upper_log)\n",
    "\n",
    "    # ÊòØÂê¶ËêΩÂú®ÂçÄÈñì\n",
    "    cover_95 = (y_test >= ci_95_lower) & (y_test <= ci_95_upper)\n",
    "    cover_99 = (y_test >= ci_99_lower) & (y_test <= ci_99_upper)\n",
    "\n",
    "    # ‰ø°ÂøÉË©ï‰º∞ÔºöË∑ùÈõ¢ CI ‰∏≠ÂøÉÁöÑÊØî‰æã\n",
    "    ci_center = (ci_95_upper + ci_95_lower) / 2\n",
    "    ci_width = ci_95_upper - ci_95_lower\n",
    "    confidence_score = 1 - np.abs(y_test - ci_center) / (ci_width + 1e-8)\n",
    "    confidence_score = np.clip(confidence_score, 0, 1)\n",
    "\n",
    "    # Áµ±Ë®àÊåáÊ®ô\n",
    "    mse = mean_squared_error(y_test, mean_pred)\n",
    "    r2 = r2_score(y_test, mean_pred)\n",
    "    cover_95_ratio = cover_95.mean()\n",
    "    cover_99_ratio = cover_99.mean()\n",
    "\n",
    "    print(f\"\\nüìä [{label}] Áµ±Ë®àÊåáÊ®ôÔºö\")\n",
    "    print(f\"   MSE         = {mse:.2f}\")\n",
    "    print(f\"   R^2         = {r2:.4f}\")\n",
    "    print(f\"   95% Ë¶ÜËìãÁéá   = {cover_95_ratio:.2%}\")\n",
    "    print(f\"   99% Ë¶ÜËìãÁéá   = {cover_99_ratio:.2%}\\n\")\n",
    "\n",
    "    # Â∞áÁµêÊûúËàá X_test ÁöÑ index ‰∏ÄËµ∑Â≠òÂÖ• DataFrame\n",
    "    df_result = pd.DataFrame({\n",
    "        \"ÂØ¶ÈöõÂÉπÊ†º\": y_test,\n",
    "        \"È†êÊ∏¨ÂÄº\": mean_pred,\n",
    "        \"CI95‰∏ãÈôê\": ci_95_lower,\n",
    "        \"CI95‰∏äÈôê\": ci_95_upper,\n",
    "        \"CI99‰∏ãÈôê\": ci_99_lower,\n",
    "        \"CI99‰∏äÈôê\": ci_99_upper,\n",
    "        \"CI95Èï∑Â∫¶\": ci_95_upper - ci_95_lower,\n",
    "        \"CI99Èï∑Â∫¶\": ci_99_upper - ci_99_lower,\n",
    "        \"ÊòØÂê¶ËêΩÂú®CI95\": cover_95.astype(int),\n",
    "        \"ÊòØÂê¶ËêΩÂú®CI99\": cover_99.astype(int),\n",
    "        \"‰ø°ÂøÉÂàÜÊï∏\": confidence_score\n",
    "    }, index=X_test.index)\n",
    "    print(f\"‚úÖ [{label}] Bootstrap CI ÁµêÊûúÁî¢ÁîüÂÆåÊàêÔºÅ\")\n",
    "    return df_result\n",
    "\n",
    "# ÂàÜÂà•ÈáùÂ∞çÁ∂ìÊøüËâôËàáÂïÜÂãôËâôÂèñÂæóÈ†êÊ∏¨ÁµêÊûúÔºàÊ≥®ÊÑèÔºöÈÄôË£°Âè™ÂåÖÂê´Ê∏¨Ë©¶ÈõÜÈÉ®ÂàÜÔºâ\n",
    "eco_result = bootstrap_prediction_ci(economy_data[eco_features], economy_data[target_col], label=\"economy\")\n",
    "biz_result = bootstrap_prediction_ci(business_data[biz_features], business_data[target_col], label=\"business\")\n",
    "\n",
    "# Â∞áÁ∂ìÊøüËâôËàáÂïÜÂãôËâôÁöÑÊ∏¨Ë©¶ÈõÜÁµêÊûúÂêà‰Ωµ\n",
    "test_result = pd.concat([eco_result, biz_result]).sort_index()\n",
    "\n",
    "# Â¶ÇÊûúÂ∏åÊúõÂêåÊôÇ‰øùÁïôÂéüÂßãË≥áÊñô‰∏≠ÁöÑÂÖ∂‰ªñË≥áË®äÔºåÂèØ‰ª•Âà©Áî® test_result ÁöÑ index ÂæûÂéüÂßãË≥áÊñô‰∏≠ÂèñÂá∫Â∞çÊáâÂàó\n",
    "# ÈÄôË£°ÂÅáË®≠ÂéüÂßãË≥áÊñôÁöÑ index Ëàá one-hot ÈÅéÂæåÁöÑË≥áÊñô index ÊòØ‰∏ÄËá¥ÁöÑ\n",
    "data_test_with_ci = data.loc[test_result.index].copy()\n",
    "data_test_with_ci = data_test_with_ci.join(test_result, how='left')\n",
    "\n",
    "# Â≠òÊ™îÂè™ÂåÖÂê´Ê∏¨Ë©¶ÈõÜËàáÈ†êÊ∏¨ÂçÄÈñìÁöÑÁµêÊûú\n",
    "output_path = '/Users/yuchingchen/Documents/Â∞àÈ°å/ci/ci_data/long_xgb_with_ci.csv'\n",
    "data_test_with_ci.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Ê∏¨Ë©¶ÈõÜÔºàÊúâÈ†êÊ∏¨ÂçÄÈñìÔºâÁµêÊûúÂ∑≤Â≠òÊ™îÔºö{output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Á∂ìÊøüËâôÁöÑÂπ≥Âùá CI95 Èï∑Â∫¶: 5745.91\n",
      "Á∂ìÊøüËâôÁöÑÂπ≥Âùá CI99 Èï∑Â∫¶: 7857.87\n",
      "ÂïÜÂãôËâôÁöÑÂπ≥Âùá CI95 Èï∑Â∫¶: 14981.74\n",
      "ÂïÜÂãôËâôÁöÑÂπ≥Âùá CI99 Èï∑Â∫¶: 20582.57\n"
     ]
    }
   ],
   "source": [
    "# ËÆÄÂÖ•Ê∏¨Ë©¶ÈõÜË≥áÊñô\n",
    "data = pd.read_csv(\"/Users/yuchingchen/Documents/Â∞àÈ°å/ci/ci_data/long_xgb_with_ci.csv\")\n",
    "\n",
    "# ÂàÜÈõ¢Á∂ìÊøüËâôËàáÂïÜÂãôËâô\n",
    "economy_data = data[data[\"ËâôÁ≠âÔºà‰∏ªËà™ÊÆµÔºâ\"] == \"Á∂ìÊøüËâô\"]\n",
    "business_data = data[data[\"ËâôÁ≠âÔºà‰∏ªËà™ÊÆµÔºâ\"] == \"ÂïÜÂãôËâô\"]\n",
    "\n",
    "# È°ØÁ§∫ CI95Èï∑Â∫¶ Ëàá CI99Èï∑Â∫¶ ÁöÑÂπ≥Âùá\n",
    "mean_ci_95_length_economy = economy_data[\"CI95Èï∑Â∫¶\"].mean()\n",
    "mean_ci_99_length_economy = economy_data[\"CI99Èï∑Â∫¶\"].mean()\n",
    "print(f\"Á∂ìÊøüËâôÁöÑÂπ≥Âùá CI95 Èï∑Â∫¶: {mean_ci_95_length_economy:.2f}\")\n",
    "print(f\"Á∂ìÊøüËâôÁöÑÂπ≥Âùá CI99 Èï∑Â∫¶: {mean_ci_99_length_economy:.2f}\")\n",
    "mean_ci_95_length_business = business_data[\"CI95Èï∑Â∫¶\"].mean()\n",
    "mean_ci_99_length_business = business_data[\"CI99Èï∑Â∫¶\"].mean()\n",
    "print(f\"ÂïÜÂãôËâôÁöÑÂπ≥Âùá CI95 Èï∑Â∫¶: {mean_ci_95_length_business:.2f}\")\n",
    "print(f\"ÂïÜÂãôËâôÁöÑÂπ≥Âùá CI99 Èï∑Â∫¶: {mean_ci_99_length_business:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
